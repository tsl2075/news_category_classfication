from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
import time
import pandas as pd
import os
from datetime import datetime

# ë©”ì¸ í¬ë¡¤ë§ í•¨ìˆ˜ ì •ì˜
def crawl_sector_news(sector, scroll_count=20): #scroll_countëŠ” ìŠ¤í¬ë¡¤ íšŸìˆ˜ ì¡°ì ˆ (ë‰´ìŠ¤ë¥¼ ë” ë§ì´ ê¸ì„ ìˆ˜ ìˆìŒ)
    print(f'ğŸ“¡ í¬ë¡¤ë§ ì‹œì‘: {sector}') # sectorëŠ” ì²˜ë¦¬í•  ì„¹í„°ëª… (ì˜ˆ: "technology")
    url = f'https://finance.yahoo.com/sectors/{sector}/'  #ê° ì„¹í„°ì˜ ë‰´ìŠ¤ í˜ì´ì§€ì— ì ‘ì†

    options = Options()
    options.add_argument("--headless")
    driver = webdriver.Chrome(service=Service(), options=options)
    driver.get(url)
    time.sleep(3)
#ìë™ ìŠ¤í¬ë¡¤ (ë™ì  ì½˜í…ì¸  ë¡œë”©)
    for _ in range(scroll_count):
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(1.5)

    titles = []
    summaries = []
    #ë‰´ìŠ¤ ìš”ì†Œ ì¶”ì¶œ
    ads = driver.find_elements(By.XPATH, '//div[contains(@id,"internal_trc_")]')
    articles = driver.find_elements(By.XPATH, '//ul/li/section/div/a')
    #ê´‘ê³ ëŠ” id="internal_trc_..."ë¡œ ì‹ë³„ â†’ í•„í„°ë§ ê°€ëŠ¥
    #ë‰´ìŠ¤ëŠ” <a> íƒœê·¸ ì•ˆì— h3(ì œëª©)ê³¼ p(ìš”ì•½)ê°€ ìˆìŒ

    #í•„í„°ë§ & í…ìŠ¤íŠ¸ ì¶”ì¶œ
    for article in articles:
        try:
            if article in ads:
                continue

            title_element = article.find_element(By.TAG_NAME, 'h3')
            summary_element = article.find_element(By.TAG_NAME, 'p')

            title = title_element.text.strip()
            summary = summary_element.text.strip()

            if len(summary) > 150:
                summary = summary[:150] + "..."

            if title and summary:
                titles.append(title)
                summaries.append(summary)
        except:
            continue

    driver.quit()

    #ë°ì´í„°í”„ë ˆì„ + ì €ì¥
    df = pd.DataFrame({
        'title': titles,
        'summary': summaries,
        'category': [sector] * len(titles)
    })
    # ì˜¤ëŠ˜ ë‚ ì§œ (ì˜ˆ: '20250421')
    today = datetime.today().strftime('%Y%m%d')

    # í´ë” ìƒì„±
    os.makedirs('news_by_sector', exist_ok=True)

    # íŒŒì¼ ì €ì¥ (ì˜ˆ: news_consumer-defensive_20250421.csv)
    df.to_csv(f'news_by_sector/news_{sector}_{today}.csv', index=False, encoding='utf-8-sig')

    print(f'âœ… ì €ì¥ ì™„ë£Œ: news_by_sector/news_{sector}.csv')

# ğŸ”½ ì²˜ë¦¬í•  ì„¹í„° ë¦¬ìŠ¤íŠ¸
sector_list = [
    'basic-materials',
    'communication-services',
    'consumer-cyclical',
    'consumer-defensive'
]

for sector in sector_list:
    crawl_sector_news(sector, scroll_count=25)
