import pandas as pd
import numpy as np
import re
import nltk
import pickle
import os
from nltk.corpus import stopwords
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical

# âœ… ë¶ˆìš©ì–´ ë‹¤ìš´ë¡œë“œ
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

# âœ… CSV íŒŒì¼ ë¡œë“œ
df = pd.read_csv('./top25_news_total.csv')
df.columns = df.columns.str.lower().str.strip()  # ì»¬ëŸ¼ ì •ë¦¬

# âœ… ì „ì²˜ë¦¬ ëŒ€ìƒ: title + summary ê²°í•©
df['text'] = df['title'].astype(str) + ' ' + df['summary'].astype(str)

# âœ… í…ìŠ¤íŠ¸ ì •ì œ í•¨ìˆ˜ ì •ì˜
def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z ]', ' ', text)
    words = text.split()
    words = [w for w in words if w not in stop_words and len(w) > 1]
    return ' '.join(words)

df['cleaned'] = df['text'].apply(clean_text)

# âœ… ì…ë ¥(X), ì •ë‹µ(Y) ë‚˜ëˆ„ê¸°
X = df['cleaned']
Y = df['category']

# âœ… ë¼ë²¨ ì¸ì½”ë”©
encoder = LabelEncoder()
encoded_y = encoder.fit_transform(Y)
onehot_y = to_categorical(encoded_y)

# âœ… í† í¬ë‚˜ì´ì €
tokenizer = Tokenizer()
tokenizer.fit_on_texts(X)
seqs = tokenizer.texts_to_sequences(X)

max_len = max(len(s) for s in seqs)
x_pad = pad_sequences(seqs, maxlen=max_len)

# âœ… ë°ì´í„° ë¶„í• 
x_train, x_test, y_train, y_test = train_test_split(x_pad, onehot_y, test_size=0.2, random_state=42)

# âœ… ì €ì¥
os.makedirs('./preprocessed', exist_ok=True)
np.save('./preprocessed/x_train.npy', x_train)
np.save('./preprocessed/x_test.npy', x_test)
np.save('./preprocessed/y_train.npy', y_train)
np.save('./preprocessed/y_test.npy', y_test)

with open(f'./preprocessed/tokenizer_maxlen{max_len}.pickle', 'wb') as f:
    pickle.dump(tokenizer, f)

with open('models/label_encoder.pickle', 'wb') as f:
    pickle.dump(encoder, f)

# âœ… ì™„ë£Œ ë¡œê·¸
print("ğŸ‰ ì „ì²˜ë¦¬ ì™„ë£Œ!")
print(f"ğŸ“¦ ì‹œí€€ìŠ¤ ìµœëŒ€ ê¸¸ì´: {max_len}")
print(f"ğŸ·ï¸ í´ë˜ìŠ¤ ëª©ë¡: {encoder.classes_.tolist()}")